{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"The AI \u200b\u200bVideo Super Resolution solution is designed to reconstruct high-resolution videos from low-resolution videos through self-developed super resolution algorithms based on deep learning, for example, a 480p video can be converted to a 1080p video. The solution allows customers to efficiently convert mass videos into high resolution and ultra-high resolution videos, so as to make full use of existing video assets. Moreover, customers can use the solution to convert video data in their own accounts. The solution mainly includes the following features: Offer pre-trained super resolution models based on self-developed algorithms; Use AWS Batch to provide parallel processing capabilities; Use AWS Inferentia to achieve high throughput inference. This implementation guide describes architectural considerations and configuration steps for deploying the AI \u200b\u200bVideo Super Resolution solution in the Amazon Web Services (AWS) cloud. It includes links to AWS CloudFormation templates that launch and configure the AWS services required to deploy this solution using AWS best practices for security and availability. The guide is intended for IT architects, developers, DevOps, data scientists, algorithm engineers, and media technicians who have practical experience architecting in the AWS Cloud.","title":"Welcome"},{"location":"additional-resources/","text":"Amazon API Gateway AWS Lambda AWS Batch Amazon S3 Amazon EFS Amazon EC2 Inf1 Instances","title":"Additional resources"},{"location":"architecture/","text":"Deploying this solution with the default parameters builds the following environment in the AWS cloud. Figure 1: Solution architecture This solution deploys the AWS CloudFormation template in your AWS cloud account and completes the following settings. Upload the original video file to the Amazon S3 bucket which will be created upon the deployment of the solution. Use Amazon API Gateway to implement HTTP API for interaction with deployed services. The AWS Lambda function receives requests. The AWS Lambda function starts the calculation job of AWS Batch . AWS Batch is used to pull pre-built model images from ECR, schedules the super resolution jobs (including video slicing, processing and merging operations) on pre-defined computing resources with scaling, and automatically releases the backend computing resources after all jobs are done. Video slicing: download the original video from the S3 bucket and split it into several slices. Super resolution processing: run a job for each slice, and perform super resolution on each slice of the video based on the pre-trained model. Merging: merge the super resolution results, and then the merged result file is uploaded to the Amazon S3 bucket. Amazon EFS is used for temporary storage of intermediate files during video processing. Amazon S3 is used to store original video assets and processed video assets. Amazon VPC is created using subnets in two Availability Zones (AZ) to achieve redundancy and ensure high availability. All resources will be deployed in both availability zones.","title":"Architecture overview"},{"location":"cost/","text":"You are responsible for the cost of using Amazon Web Service's services used while running this solution. As of November 2021, in the AWS Oregon Region (us-west-2), for 540p to 4K super resolution tasks, the estimated cost of running the solution to process the original video is approximately $8.86 per hour. Formula for cost estimate The cost mainly depends on Amazon EC2 launched by AWS Batch, and the actual cost may include charges incurred for Amazon S3, Amazon EFS, and AWS Lambda. Use the following formula for cost estimate: {Video Height} * {Video Width} * {Frame Rate} * 3e-6 = The number of charging seconds corresponding to the original video per second Example 1 In AWS Oregon Region (us-west-2), for a 540p (960*540) video (~200MB), the number of charging seconds corresponding to the original video per second is 960*540*25*3e-6=38.88 seconds. Suppose the video is 30 minutes (1800 seconds) in length, which corresponds to 1800*38.88=69984 seconds=19.44 hours. So the cost is: OnDemand: 19.44 hours*$0.228 = $4.43 Spot: 19.44 hours*$0.0684 = $1.32 AWS service Dimensions Cost Amazon EC2 Launched by AWS batch, 0.228 per hour (inf1.xlarge) $4.43 Amazon S3 2 GET requests + 1 PUT request, 200MB+600MB (Approximate), 1 month $0.023 AWS Lambda 1 request (~5s, 4096MB Memory) $0.0007 Amazon EFS 200MB, 19.44 hours $0.0015 TOTAL: $4.4552 Example 2 In AWS China (Ningxia) Region operated by NWCD (cn-northwest-1), for a 1080p (1920*1080) video (~1000MB), the number of charging seconds corresponding to the original video per second is 1920*1080*25*3e-6=155.52 seconds. Suppose the video is 30 minutes (1800 seconds) in length, which corresponds to 1800*155.52=279936 seconds=77.76 hours. So the cost is: OnDemand: 77.76 hours*\u00a52.601 = \u00a5202.25 Spot: 77.76 hours*\u00a50.4839 = \u00a537.62 AWS service Dimensions Cost Amazon EC2 Launched by AWS batch, 2.601 per hour (inf1.xlarge) \u00a5202.25 Amazon S3 2 GET requests + 1 PUT request, 1000MB+4000MB (Approximate), 1 month \u00a50.877 AWS Lambda 1 request (~5s, 4096MB Memory) \u00a50.002 Amazon EFS 1000MB, 77.76 hours \u00a50.228 TOTAL: \u00a5203.357","title":"Cost"},{"location":"cost/#formula-for-cost-estimate","text":"The cost mainly depends on Amazon EC2 launched by AWS Batch, and the actual cost may include charges incurred for Amazon S3, Amazon EFS, and AWS Lambda. Use the following formula for cost estimate: {Video Height} * {Video Width} * {Frame Rate} * 3e-6 = The number of charging seconds corresponding to the original video per second","title":"Formula for cost estimate"},{"location":"cost/#example-1","text":"In AWS Oregon Region (us-west-2), for a 540p (960*540) video (~200MB), the number of charging seconds corresponding to the original video per second is 960*540*25*3e-6=38.88 seconds. Suppose the video is 30 minutes (1800 seconds) in length, which corresponds to 1800*38.88=69984 seconds=19.44 hours. So the cost is: OnDemand: 19.44 hours*$0.228 = $4.43 Spot: 19.44 hours*$0.0684 = $1.32 AWS service Dimensions Cost Amazon EC2 Launched by AWS batch, 0.228 per hour (inf1.xlarge) $4.43 Amazon S3 2 GET requests + 1 PUT request, 200MB+600MB (Approximate), 1 month $0.023 AWS Lambda 1 request (~5s, 4096MB Memory) $0.0007 Amazon EFS 200MB, 19.44 hours $0.0015 TOTAL: $4.4552","title":"Example 1"},{"location":"cost/#example-2","text":"In AWS China (Ningxia) Region operated by NWCD (cn-northwest-1), for a 1080p (1920*1080) video (~1000MB), the number of charging seconds corresponding to the original video per second is 1920*1080*25*3e-6=155.52 seconds. Suppose the video is 30 minutes (1800 seconds) in length, which corresponds to 1800*155.52=279936 seconds=77.76 hours. So the cost is: OnDemand: 77.76 hours*\u00a52.601 = \u00a5202.25 Spot: 77.76 hours*\u00a50.4839 = \u00a537.62 AWS service Dimensions Cost Amazon EC2 Launched by AWS batch, 2.601 per hour (inf1.xlarge) \u00a5202.25 Amazon S3 2 GET requests + 1 PUT request, 1000MB+4000MB (Approximate), 1 month \u00a50.877 AWS Lambda 1 request (~5s, 4096MB Memory) \u00a50.002 Amazon EFS 1000MB, 77.76 hours \u00a50.228 TOTAL: \u00a5203.357","title":"Example 2"},{"location":"deployment/","text":"Before you launch the solution, review the architecture, supported regions, and other considerations discussed in this guide. Follow the step-by-step instructions in this section to configure and deploy the solution into your account. Time to deploy : Approximately 10 minutes Overview Complete the following steps in your AWS account. Step 1: Launch the AWS CloudFormation template Step 2: Create a super resolution task Important Make sure you have sufficient EC2 quotas (such as inf1 instances vcpu) to run Batch jobs. Step 1: Launch the AWS CloudFormation template This automated AWS CloudFormation template deploys the solution in the AWS Cloud. Sign in to the AWS Management Console and use one of the buttons below to launch the AWS CloudFormation template. Alternatively, you can download the template as a starting point for your own implementation. Launch solution in AWS Standard Regions Launch solution in AWS China Regions By default, the template launches in the default Region you have logged in. To launch this solution in a different AWS Region, use the Region selector in the console navigation bar. On the Create stack page, verify that the correct template URL is shown in the Amazon S3 URL text box and choose Next . On the Specify stack details page, assign a valid and account level unique name to your solution stack. This ensures all the resources in the stack remain under the maximum length allowed by CloudFormation. For information about naming character limitations, refer to IAM and STS Limits in the AWS Identity and Access Management User Guide . Under Parameters , review the parameters for the template and modify them as necessary. This solution uses the following default values. Parameter Default Description MaxvCpus 16 The maximum vcpu limit of the instance called by the Batch job, which will affect the number of nodes that the Batch starts. By default, the instance of inf1.xlarge has 4 vcpus. When MaxvCpus is set to 16, 16/4=4 instances will be started. Choose Next . On the Configure stack options page, choose Next . On the Review page, review and confirm the settings. Check the box acknowledging that the template will create AWS Identity and Access Management (IAM) resources. Choose Create stack to deploy the stack. You can view the status of the stack in the AWS CloudFormation Console in the Status column. You should receive a CREATE_COMPLETE status in approximately 10 minutes. After the stack is created successfully, you can see the endpoint URL in Outputs tab of AWS Cloudformation. Step 2: Create a super resolution task To create a super resolution task, you need to send a request with the following parameters to the endpoint URL. Parameter Default Description key <Requires input> Indicates the file name in S3. scale 2 Defines super resolution scaling (one-sided). The allowed values are 2 or 4. task inference Specifies the task type. The allowed values are debug or inference. When it is set to debug, all intermediate files will be uploaded to S3 for debugging purposes. env spot Specifies the Job running environment. The allowed values are onDemand or spot. The following example shows the request code after the deployment with default configurations. cURL curl --location --request POST 'https://xxxxx.execute-api.xxxxx.amazonaws.com/prod' \\ --header 'Content-Type: application/json' \\ --data-raw '{ \"key\": \"xxxx.mp4\" }' Python (requests) import requests import json url = \"https://xxxxx.execute-api.xxxxx.amazonaws.com/prod\" payload = json.dumps({ \"key\": \"xxxx.mp4\" }) headers = { 'Content-Type': 'application/json' } response = requests.request(\"POST\", url, headers=headers, data=payload) print(response.text) Java (OkHttp) OkHttpClient client = new OkHttpClient().newBuilder() .build(); MediaType mediaType = MediaType.parse(\"application/json\"); RequestBody body = RequestBody.create(mediaType, \"{\\n \\\"key\\\": \\\"xxxx.mp4\\\"\\n}\"); Request request = new Request.Builder() .url(\"https://xxxxx.execute-api.xxxxx.amazonaws.com/prod\") .method(\"POST\", body) .addHeader(\"Content-Type\", \"application/json\") .build(); Response response = client.newCall(request).execute(); PHP (curl) <?php $curl = curl_init(); curl_setopt_array($curl, array( CURLOPT_URL => 'https://xxxxx.execute-api.xxxxx.amazonaws.com/prod', CURLOPT_RETURNTRANSFER => true, CURLOPT_ENCODING => '', CURLOPT_MAXREDIRS => 10, CURLOPT_TIMEOUT => 0, CURLOPT_FOLLOWLOCATION => true, CURLOPT_HTTP_VERSION => CURL_HTTP_VERSION_1_1, CURLOPT_CUSTOMREQUEST => 'POST', CURLOPT_POSTFIELDS =>'{ \"key\": \"xxxx.mp4\" }', CURLOPT_HTTPHEADER => array( 'Content-Type: application/json' ), )); $response = curl_exec($curl); curl_close($curl); echo $response;","title":"Automated deployment"},{"location":"deployment/#overview","text":"Complete the following steps in your AWS account. Step 1: Launch the AWS CloudFormation template Step 2: Create a super resolution task Important Make sure you have sufficient EC2 quotas (such as inf1 instances vcpu) to run Batch jobs.","title":"Overview"},{"location":"deployment/#step-1-launch-the-aws-cloudformation-template","text":"This automated AWS CloudFormation template deploys the solution in the AWS Cloud. Sign in to the AWS Management Console and use one of the buttons below to launch the AWS CloudFormation template. Alternatively, you can download the template as a starting point for your own implementation. Launch solution in AWS Standard Regions Launch solution in AWS China Regions By default, the template launches in the default Region you have logged in. To launch this solution in a different AWS Region, use the Region selector in the console navigation bar. On the Create stack page, verify that the correct template URL is shown in the Amazon S3 URL text box and choose Next . On the Specify stack details page, assign a valid and account level unique name to your solution stack. This ensures all the resources in the stack remain under the maximum length allowed by CloudFormation. For information about naming character limitations, refer to IAM and STS Limits in the AWS Identity and Access Management User Guide . Under Parameters , review the parameters for the template and modify them as necessary. This solution uses the following default values. Parameter Default Description MaxvCpus 16 The maximum vcpu limit of the instance called by the Batch job, which will affect the number of nodes that the Batch starts. By default, the instance of inf1.xlarge has 4 vcpus. When MaxvCpus is set to 16, 16/4=4 instances will be started. Choose Next . On the Configure stack options page, choose Next . On the Review page, review and confirm the settings. Check the box acknowledging that the template will create AWS Identity and Access Management (IAM) resources. Choose Create stack to deploy the stack. You can view the status of the stack in the AWS CloudFormation Console in the Status column. You should receive a CREATE_COMPLETE status in approximately 10 minutes. After the stack is created successfully, you can see the endpoint URL in Outputs tab of AWS Cloudformation.","title":"Step 1: Launch the AWS CloudFormation template"},{"location":"deployment/#step-2-create-a-super-resolution-task","text":"To create a super resolution task, you need to send a request with the following parameters to the endpoint URL. Parameter Default Description key <Requires input> Indicates the file name in S3. scale 2 Defines super resolution scaling (one-sided). The allowed values are 2 or 4. task inference Specifies the task type. The allowed values are debug or inference. When it is set to debug, all intermediate files will be uploaded to S3 for debugging purposes. env spot Specifies the Job running environment. The allowed values are onDemand or spot. The following example shows the request code after the deployment with default configurations. cURL curl --location --request POST 'https://xxxxx.execute-api.xxxxx.amazonaws.com/prod' \\ --header 'Content-Type: application/json' \\ --data-raw '{ \"key\": \"xxxx.mp4\" }' Python (requests) import requests import json url = \"https://xxxxx.execute-api.xxxxx.amazonaws.com/prod\" payload = json.dumps({ \"key\": \"xxxx.mp4\" }) headers = { 'Content-Type': 'application/json' } response = requests.request(\"POST\", url, headers=headers, data=payload) print(response.text) Java (OkHttp) OkHttpClient client = new OkHttpClient().newBuilder() .build(); MediaType mediaType = MediaType.parse(\"application/json\"); RequestBody body = RequestBody.create(mediaType, \"{\\n \\\"key\\\": \\\"xxxx.mp4\\\"\\n}\"); Request request = new Request.Builder() .url(\"https://xxxxx.execute-api.xxxxx.amazonaws.com/prod\") .method(\"POST\", body) .addHeader(\"Content-Type\", \"application/json\") .build(); Response response = client.newCall(request).execute(); PHP (curl) <?php $curl = curl_init(); curl_setopt_array($curl, array( CURLOPT_URL => 'https://xxxxx.execute-api.xxxxx.amazonaws.com/prod', CURLOPT_RETURNTRANSFER => true, CURLOPT_ENCODING => '', CURLOPT_MAXREDIRS => 10, CURLOPT_TIMEOUT => 0, CURLOPT_FOLLOWLOCATION => true, CURLOPT_HTTP_VERSION => CURL_HTTP_VERSION_1_1, CURLOPT_CUSTOMREQUEST => 'POST', CURLOPT_POSTFIELDS =>'{ \"key\": \"xxxx.mp4\" }', CURLOPT_HTTPHEADER => array( 'Content-Type: application/json' ), )); $response = curl_exec($curl); curl_close($curl); echo $response;","title":"Step 2: Create a super resolution task"},{"location":"notices/","text":"Customers are responsible for making their own independent assessment of the information in this document. This document: (a) is for informational purposes only, (b) represents Amazon Web Services current product offerings and practices, which are subject to change without notice, and (c) does not create any commitments or assurances from Amazon Web Services and its affiliates, suppliers or licensors. Amazon Web Services products or services are provided \"as is\" without warranties, representations, or conditions of any kind, whether express or implied. Amazon Web Services responsibilities and liabilities to its customers are controlled by Amazon Web Services agreements, and this document is not part of, nor does it modify, any agreement between Amazon Web Services and its customers. The AI Video Super Resolution solution is licensed under the terms of the Apache License Version 2.0 available at The Apache Software Foundation .","title":"Notices"},{"location":"regions/","text":"This solution uses services which may not be currently available in all AWS Regions. Launch this solution in an AWS Region where required services are available. For the most current availability by Region, refer to the AWS Regional Services List. As of November 2021, this solution is supported in the following Amazon Web Services Regions: Supported regions for deployment in AWS Standard Regions Region Name Region ID US East (N. Virginia) us-east-1 US East (Ohio) us-east-2 US West (Oregon) us-west-2 Asia Pacific (Mumbai) ap-south-1 Asia Pacific (Tokyo) ap-northeast-1 Asia Pacific (Seoul) ap-northeast-2 Asia Pacific (Singapore) ap-southeast-1 Asia Pacific (Sydney) ap-southeast-2 Canada (Central) ca-central-1 Europe (Ireland) eu-west-1 Europe (London) eu-west-2 Europe (Paris) eu-west-3 Europe (Frankfurt) eu-central-1 South America (S\u00e3o Paulo) sa-east-1 Supported regions for deployment in AWS China Regions Region Name Region ID China (Beijing) Region operated by Sinnet cn-north-1 China (Ningxia) Region operated by NWCD cn-northwest-1","title":"Supported regions"},{"location":"regions/#supported-regions-for-deployment-in-aws-standard-regions","text":"Region Name Region ID US East (N. Virginia) us-east-1 US East (Ohio) us-east-2 US West (Oregon) us-west-2 Asia Pacific (Mumbai) ap-south-1 Asia Pacific (Tokyo) ap-northeast-1 Asia Pacific (Seoul) ap-northeast-2 Asia Pacific (Singapore) ap-southeast-1 Asia Pacific (Sydney) ap-southeast-2 Canada (Central) ca-central-1 Europe (Ireland) eu-west-1 Europe (London) eu-west-2 Europe (Paris) eu-west-3 Europe (Frankfurt) eu-central-1 South America (S\u00e3o Paulo) sa-east-1","title":"Supported regions for deployment in AWS Standard Regions"},{"location":"regions/#supported-regions-for-deployment-in-aws-china-regions","text":"Region Name Region ID China (Beijing) Region operated by Sinnet cn-north-1 China (Ningxia) Region operated by NWCD cn-northwest-1","title":"Supported regions for deployment in AWS China Regions"},{"location":"revisions/","text":"Date Change November 2021 Intitial release","title":"Revisions"},{"location":"security/","text":"When you build systems on AWS infrastructure, security responsibilities are shared between you and AWS. This shared model reduces your operational burden because AWS operates, manages, and controls the components including the host operating system, the virtualization layer, and the physical security of the facilities in which the services operate. For more information about AWS security, visit AWS Cloud Security . IAM roles AWS Identity and Access Management (IAM) roles allow customers to assign granular access policies and permissions to services and users on the AWS Cloud. This solution creates IAM roles that grant the solution\u2019s access between the solution components. Security groups The security groups created in this solution are designed to control and isolate network traffic between the solution components. We recommend that you review the security groups and further restrict access as needed once the deployment is up and running.","title":"Security"},{"location":"security/#iam-roles","text":"AWS Identity and Access Management (IAM) roles allow customers to assign granular access policies and permissions to services and users on the AWS Cloud. This solution creates IAM roles that grant the solution\u2019s access between the solution components.","title":"IAM roles"},{"location":"security/#security-groups","text":"The security groups created in this solution are designed to control and isolate network traffic between the solution components. We recommend that you review the security groups and further restrict access as needed once the deployment is up and running.","title":"Security groups"},{"location":"source/","text":"Visit our GitHub repository to download the templates and scripts for this solution. The AI Video Super Resolution template is generated using the AWS Cloud Development Kit (CDK) . Refer to the README.md file for additional information.","title":"Source code"},{"location":"template/","text":"To automate deployment, this solution uses the following AWS CloudFormation templates, which you can download before deployment: SuperResolutionStack.template : Use this template to launch the solution and all associated components. The default configuration deploys Amazon API Gateway , AWS Lambda , AWS Batch , Amazon S3 , and Amazon EFS , but you can customize the template to meet your specific needs.","title":"AWS CloudFormation template"},{"location":"uninstall/","text":"To uninstall the AI Video Super Resolution solution, you must delete the AWS CloudFormation stack. You can use the AWS Management Console or the AWS Command Line Interface (AWS CLI) to delete the CloudFormation stack. Important Because two S3 buckets starting with superresolutionstack-superresolutionstorage and superresolutionstack-superresolutionbucketaccessl will persist while you delete the stack, make sure to empty the two buckets before deleting the AWS CloudFormation stack. Uninstall the stack using the AWS Management Console Sign in to the AWS CloudFormation console. Select this solution\u2019s installation parent stack. Choose Delete . Uninstall the stack using AWS Command Line Interface Determine whether the AWS Command Line Interface (AWS CLI) is available in your environment. For installation instructions, refer to What Is the AWS Command Line Interface in the AWS CLI User Guide . After confirming that the AWS CLI is available, run the following command. aws cloudformation delete-stack --stack-name <installation-stack-name> --region <aws-region> Deleting the Amazon S3 buckets The solution creates two S3 buckets that are not automatically deleted. You can choose to follow the following steps to delete these buckets manually. Sign in to the Amazon S3 console. Select the bucket name starting with superresolutionstack-superresolutionstorage . Choose Empty . Choose Delete . Select the bucket name starting with superresolutionstack-superresolutionbucketaccessl . Choose Empty . Choose Delete . To delete the S3 bucket using AWS CLI, run the following command: aws s3 rb s3://<bucket-name> --force","title":"Uninstall the solution"},{"location":"uninstall/#uninstall-the-stack-using-the-aws-management-console","text":"Sign in to the AWS CloudFormation console. Select this solution\u2019s installation parent stack. Choose Delete .","title":"Uninstall the stack using the AWS Management Console"},{"location":"uninstall/#uninstall-the-stack-using-aws-command-line-interface","text":"Determine whether the AWS Command Line Interface (AWS CLI) is available in your environment. For installation instructions, refer to What Is the AWS Command Line Interface in the AWS CLI User Guide . After confirming that the AWS CLI is available, run the following command. aws cloudformation delete-stack --stack-name <installation-stack-name> --region <aws-region>","title":"Uninstall the stack using AWS Command Line Interface"},{"location":"uninstall/#deleting-the-amazon-s3-buckets","text":"The solution creates two S3 buckets that are not automatically deleted. You can choose to follow the following steps to delete these buckets manually. Sign in to the Amazon S3 console. Select the bucket name starting with superresolutionstack-superresolutionstorage . Choose Empty . Choose Delete . Select the bucket name starting with superresolutionstack-superresolutionbucketaccessl . Choose Empty . Choose Delete . To delete the S3 bucket using AWS CLI, run the following command: aws s3 rb s3://<bucket-name> --force","title":"Deleting the Amazon S3 buckets"}]}